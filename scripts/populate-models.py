#!/usr/bin/env python3
"""
DynamoDBã«Ollamaãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’æŠ•å…¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import boto3
import json
from datetime import datetime

def populate_models():
    # DynamoDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    dynamodb = boto3.resource('dynamodb')
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆç’°å¢ƒã«å¿œã˜ã¦å¤‰æ›´ï¼‰
    table_name = 'production-ollama-models'
    table = dynamodb.Table(table_name)
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
    models = [
        {
            'id': 'llama2:7b',
            'name': 'Llama 2 7B',
            'description': 'æ±ç”¨çš„ãªå¯¾è©±å‹AIã€‚ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½ã§å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œ',
            'size': '7B parameters',
            'memoryRequired': '4GB',
            'estimatedStartTime': '2-3åˆ†',
            'category': 'chat',
            'isPopular': True,
            'ollama_model_name': 'llama2:7b',
            'min_memory_gb': 4,
            'recommended_cpu': 2,
            'supports_gpu': True,
            'created_at': datetime.utcnow().isoformat(),
            'status': 'available'
        },
        {
            'id': 'llama2:13b',
            'name': 'Llama 2 13B',
            'description': 'é«˜æ€§èƒ½ãªå¯¾è©±å‹AIã€‚ã‚ˆã‚Šè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚„é•·ã„æ–‡è„ˆã®ç†è§£ãŒå¯èƒ½',
            'size': '13B parameters',
            'memoryRequired': '8GB',
            'estimatedStartTime': '3-4åˆ†',
            'category': 'chat',
            'isPopular': True,
            'ollama_model_name': 'llama2:13b',
            'min_memory_gb': 8,
            'recommended_cpu': 4,
            'supports_gpu': True,
            'created_at': datetime.utcnow().isoformat(),
            'status': 'available'
        },
        {
            'id': 'codellama:7b',
            'name': 'Code Llama 7B',
            'description': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ç‰¹åŒ–å‹AIã€‚ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€ãƒ‡ãƒãƒƒã‚°ã€èª¬æ˜ã«æœ€é©',
            'size': '7B parameters',
            'memoryRequired': '4GB',
            'estimatedStartTime': '2-3åˆ†',
            'category': 'code',
            'isPopular': True,
            'ollama_model_name': 'codellama:7b',
            'min_memory_gb': 4,
            'recommended_cpu': 2,
            'supports_gpu': True,
            'created_at': datetime.utcnow().isoformat(),
            'status': 'available'
        },
        {
            'id': 'codellama:13b',
            'name': 'Code Llama 13B',
            'description': 'é«˜æ€§èƒ½ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°AIã€‚è¤‡é›‘ãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°',
            'size': '13B parameters',
            'memoryRequired': '8GB',
            'estimatedStartTime': '3-4åˆ†',
            'category': 'code',
            'isPopular': False,
            'ollama_model_name': 'codellama:13b',
            'min_memory_gb': 8,
            'recommended_cpu': 4,
            'supports_gpu': True,
            'created_at': datetime.utcnow().isoformat(),
            'status': 'available'
        },
        {
            'id': 'mistral:7b',
            'name': 'Mistral 7B',
            'description': 'åŠ¹ç‡çš„ã§é«˜é€Ÿãªæ¨è«–ãŒå¯èƒ½ãªæ±ç”¨ãƒ¢ãƒ‡ãƒ«',
            'size': '7B parameters',
            'memoryRequired': '4GB',
            'estimatedStartTime': '2-3åˆ†',
            'category': 'text',
            'isPopular': False,
            'ollama_model_name': 'mistral:7b',
            'min_memory_gb': 4,
            'recommended_cpu': 2,
            'supports_gpu': True,
            'created_at': datetime.utcnow().isoformat(),
            'status': 'available'
        },
        {
            'id': 'mistral:7b-instruct',
            'name': 'Mistral 7B Instruct',
            'description': 'æŒ‡ç¤ºã«å¾“ã†ã“ã¨ã«ç‰¹åŒ–ã—ãŸMistralãƒ¢ãƒ‡ãƒ«',
            'size': '7B parameters',
            'memoryRequired': '4GB',
            'estimatedStartTime': '2-3åˆ†',
            'category': 'chat',
            'isPopular': False,
            'ollama_model_name': 'mistral:7b-instruct',
            'min_memory_gb': 4,
            'recommended_cpu': 2,
            'supports_gpu': True,
            'created_at': datetime.utcnow().isoformat(),
            'status': 'available'
        }
    ]
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’æŠ•å…¥
    for model in models:
        try:
            table.put_item(Item=model)
            print(f"âœ… Added model: {model['name']}")
        except Exception as e:
            print(f"âŒ Failed to add model {model['name']}: {str(e)}")
    
    print(f"\nğŸ‰ Model population completed! Added {len(models)} models to {table_name}")

if __name__ == '__main__':
    populate_models()
